{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NVDA Stock Forecasting: ML → Monte Carlo Pipeline\n",
        "\n",
        "Minimal ML baseline + Monte Carlo simulation with HPC-ready placeholder (Numba).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Imports and environment\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Try to import numba\n",
        "try:\n",
        "    from numba import njit, prange\n",
        "    NUMBA_AVAILABLE = True\n",
        "    print(\"✓ Numba available - HPC backend enabled\")\n",
        "except ImportError:\n",
        "    NUMBA_AVAILABLE = False\n",
        "    print(\"⚠ Numba not available - using serial backend\")\n",
        "\n",
        "# Paths\n",
        "CSV_PATH = \"../examples/NVDA_data_2010_2025.csv\"\n",
        "os.makedirs(\"../outputs\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load & Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CSV and preprocess\n",
        "df = pd.read_csv(CSV_PATH, parse_dates=[\"date\"])\n",
        "df = df[df[\"ticker\"] == \"NVDA\"].copy()\n",
        "\n",
        "# Compute 30-day rolling features\n",
        "df[\"mu_rolling\"] = df[\"log_returns\"].rolling(30).mean()\n",
        "df[\"sigma_rolling\"] = df[\"log_returns\"].rolling(30).std()\n",
        "\n",
        "# Drop NaN\n",
        "df = df.dropna(subset=[\"mu_rolling\", \"sigma_rolling\"])\n",
        "\n",
        "# Keep minimal columns\n",
        "df = df[[\"date\", \"ticker\", \"close\", \"log_returns\", \"mu_rolling\", \"sigma_rolling\"]]\n",
        "\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "df.info()\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. ML Baseline: Predict Next-Day Returns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build windowed features: predict next-day log_returns from 30-day window\n",
        "WINDOW = 30\n",
        "log_rets = df[\"log_returns\"].values\n",
        "N = len(log_rets)\n",
        "\n",
        "X, y = [], []\n",
        "for i in range(N - WINDOW):\n",
        "    X.append(log_rets[i:i+WINDOW])\n",
        "    y.append(log_rets[i+WINDOW])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Train/test split (80/20)\n",
        "split_idx = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "# Fit linear regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"ML R² Score: {r2:.4f}\")\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(y_test[:200], label=\"Actual\", alpha=0.7)\n",
        "plt.plot(y_pred[:200], label=\"Predicted\", alpha=0.7)\n",
        "plt.xlabel(\"Test Sample\")\n",
        "plt.ylabel(\"Log Returns\")\n",
        "plt.title(\"ML Predictions: Actual vs Predicted\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save ML predictions\n",
        "dates_test = df[\"date\"].values[WINDOW + split_idx:]\n",
        "ml_pred_df = pd.DataFrame({\n",
        "    \"date\": dates_test,\n",
        "    \"y_true\": y_test,\n",
        "    \"y_pred\": y_pred\n",
        "})\n",
        "ml_pred_df.to_csv(\"../outputs/nvda_ml_pred.csv\", index=False)\n",
        "print(f\"✓ Saved: outputs/nvda_ml_pred.csv\")\n",
        "ml_pred_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Rolling Forecast: Year-by-Year Predictions\n",
        "\n",
        "Implement three training window setups: Expanding-Long / Sliding-5y / Sliding-3y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling forecast implementation\n",
        "# Define periods and training window setups\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Define train/test periods\n",
        "df['year'] = df['date'].dt.year\n",
        "test_years = [2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
        "train_windows = {\n",
        "    'Expanding-Long': lambda df, test_year: df[df['year'] < test_year],\n",
        "    'Sliding-5y': lambda df, test_year: df[(df['year'] >= test_year - 5) & (df['year'] < test_year)],\n",
        "    'Sliding-3y': lambda df, test_year: df[(df['year'] >= test_year - 3) & (df['year'] < test_year)]\n",
        "}\n",
        "\n",
        "WINDOW = 30\n",
        "results_forecast = []\n",
        "\n",
        "for test_year in test_years:\n",
        "    test_df = df[df['year'] == test_year]\n",
        "    if len(test_df) < 30:\n",
        "        print(f\"⚠ Skipping {test_year}: insufficient data ({len(test_df)} days)\")\n",
        "        continue\n",
        "    \n",
        "    for setup_name, get_train_window in train_windows.items():\n",
        "        train_df = get_train_window(df, test_year)\n",
        "        if len(train_df) < WINDOW * 2:\n",
        "            print(f\"⚠ Skipping {test_year}×{setup_name}: insufficient training data\")\n",
        "            continue\n",
        "        \n",
        "        # Build features\n",
        "        train_log_rets = train_df['log_returns'].values\n",
        "        test_log_rets = test_df['log_returns'].values\n",
        "        \n",
        "        # Train\n",
        "        X_train, y_train = [], []\n",
        "        for i in range(len(train_log_rets) - WINDOW):\n",
        "            X_train.append(train_log_rets[i:i+WINDOW])\n",
        "            y_train.append(train_log_rets[i+WINDOW])\n",
        "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "        \n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # Test\n",
        "        X_test, y_test = [], []\n",
        "        for i in range(len(test_log_rets) - WINDOW):\n",
        "            X_test.append(test_log_rets[i:i+WINDOW])\n",
        "            y_test.append(test_log_rets[i+WINDOW])\n",
        "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "        \n",
        "        if len(y_test) == 0:\n",
        "            continue\n",
        "        \n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        sign_acc = np.mean(np.sign(y_test) == np.sign(y_pred))\n",
        "        ic = np.corrcoef(y_test, y_pred)[0, 1]\n",
        "        \n",
        "        results_forecast.append({\n",
        "            'year': test_year,\n",
        "            'setup': setup_name,\n",
        "            'R²': r2,\n",
        "            'MAE': mae,\n",
        "            'sign_acc': sign_acc,\n",
        "            'IC': ic,\n",
        "            'n_samples': len(y_test)\n",
        "        })\n",
        "        \n",
        "        print(f\"{test_year}×{setup_name}: R²={r2:.4f}, sign_acc={sign_acc:.3f}\")\n",
        "\n",
        "# Save results\n",
        "results_df = pd.DataFrame(results_forecast)\n",
        "results_df.to_csv(\"../outputs/results_forecast.csv\", index=False)\n",
        "print(f\"\\n✓ Saved: outputs/results_forecast.csv\")\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Monte Carlo Simulation (Serial & Numba Backends)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monte Carlo parameters\n",
        "STEPS = 252\n",
        "N_PATHS = 5000\n",
        "S0 = df[\"close\"].iloc[-1]\n",
        "MU = df[\"mu_rolling\"].iloc[-1]\n",
        "SIGMA = df[\"sigma_rolling\"].iloc[-1]\n",
        "DT = 1 / 252\n",
        "\n",
        "print(f\"MC Parameters:\")\n",
        "print(f\"  S0 = ${S0:.2f}\")\n",
        "print(f\"  μ (annualized) = {MU * 252:.4f}\")\n",
        "print(f\"  σ (annualized) = {SIGMA * np.sqrt(252):.4f}\")\n",
        "print(f\"  Steps = {STEPS}\")\n",
        "print(f\"  Paths = {N_PATHS}\")\n",
        "\n",
        "# Serial backend\n",
        "def simulate_paths_serial(mu, sigma, s0, steps=252, n_paths=5000, dt=1/252):\n",
        "    \"\"\"Plain NumPy loop implementation.\"\"\"\n",
        "    np.random.seed(42)\n",
        "    paths = np.zeros((n_paths, steps))\n",
        "    for i in range(n_paths):\n",
        "        s = s0\n",
        "        for j in range(steps):\n",
        "            z = np.random.normal()\n",
        "            s *= np.exp((mu - 0.5*sigma**2)*dt + sigma*np.sqrt(dt)*z)\n",
        "            paths[i, j] = s\n",
        "    return paths\n",
        "\n",
        "# Numba HPC backend (if available)\n",
        "if NUMBA_AVAILABLE:\n",
        "    @njit(parallel=True, fastmath=True)\n",
        "    def simulate_paths_numba(mu, sigma, s0, steps=252, n_paths=5000, dt=1/252):\n",
        "        \"\"\"Numba-parallelized implementation.\"\"\"\n",
        "        out = np.empty((n_paths, steps))\n",
        "        for i in prange(n_paths):\n",
        "            s = s0\n",
        "            for j in range(steps):\n",
        "                z = np.random.normal()\n",
        "                s *= np.exp((mu - 0.5*sigma*sigma)*dt + sigma*np.sqrt(dt)*z)\n",
        "                out[i, j] = s\n",
        "        return out\n",
        "\n",
        "# Runtime helper\n",
        "def run_mc(mu, sigma, s0, steps=252, n_paths=5000, use_numba=False):\n",
        "    \"\"\"Run MC simulation and return paths, backend name, and runtime.\"\"\"\n",
        "    t0 = time.time()\n",
        "    if use_numba and NUMBA_AVAILABLE:\n",
        "        paths = simulate_paths_numba(mu, sigma, s0, steps, n_paths, dt=1/252)\n",
        "        backend = \"numba\"\n",
        "    else:\n",
        "        paths = simulate_paths_serial(mu, sigma, s0, steps, n_paths, dt=1/252)\n",
        "        backend = \"serial\"\n",
        "    secs = time.time() - t0\n",
        "    return paths, backend, secs\n",
        "\n",
        "# Run both backends\n",
        "print(\"\\nRunning simulations...\")\n",
        "paths_serial, b1, t1 = run_mc(MU, SIGMA, S0, STEPS, N_PATHS, use_numba=False)\n",
        "paths_fast, b2, t2 = run_mc(MU, SIGMA, S0, STEPS, N_PATHS, use_numba=True)\n",
        "\n",
        "print(f\"\\nTimings:\")\n",
        "print(f\"  Serial: {t1:.3f}s ({b1})\")\n",
        "print(f\"  {'Numba' if NUMBA_AVAILABLE else 'Fallback'}: {t2:.3f}s ({b2})\")\n",
        "if NUMBA_AVAILABLE:\n",
        "    print(f\"  Speedup: {t1/t2:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualizations & Outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use fastest backend\n",
        "paths = paths_fast if NUMBA_AVAILABLE else paths_serial\n",
        "\n",
        "# Plot: sample paths\n",
        "n_sample = min(50, N_PATHS)\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Sample paths\n",
        "sample_indices = np.random.choice(N_PATHS, n_sample, replace=False)\n",
        "for idx in sample_indices:\n",
        "    ax1.plot(paths[idx, :], alpha=0.2, linewidth=0.5)\n",
        "ax1.axhline(S0, color='red', linewidth=2, label=f'S0=${S0:.2f}')\n",
        "ax1.set_xlabel('Days')\n",
        "ax1.set_ylabel('Price ($)')\n",
        "ax1.set_title(f'Sample {n_sample} MC Paths')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Terminal distribution\n",
        "terminals = paths[:, -1]\n",
        "p5, p50, p95 = np.percentile(terminals, [5, 50, 95])\n",
        "ax2.hist(terminals, bins=50, alpha=0.7, edgecolor='black')\n",
        "ax2.axvline(p50, color='red', linewidth=2, label=f'Median=${p50:.2f}')\n",
        "ax2.axvline(p5, color='orange', linestyle='--', label=f'P5=${p5:.2f}')\n",
        "ax2.axvline(p95, color='orange', linestyle='--', label=f'P95=${p95:.2f}')\n",
        "ax2.set_xlabel('Terminal Price ($)')\n",
        "ax2.set_ylabel('Frequency')\n",
        "ax2.set_title('Distribution of Terminal Prices')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Terminal Price Quantiles:\")\n",
        "print(f\"  P5  = ${p5:.2f}\")\n",
        "print(f\"  P50 = ${p50:.2f}\")\n",
        "print(f\"  P95 = ${p95:.2f}\")\n",
        "\n",
        "# Save outputs\n",
        "pd.DataFrame({\"terminal_price\": terminals}).to_csv(\"../outputs/nvda_mc_terminals.csv\", index=False)\n",
        "print(f\"✓ Saved: outputs/nvda_mc_terminals.csv\")\n",
        "\n",
        "import json\n",
        "meta = {\n",
        "    \"S0\": float(S0),\n",
        "    \"MU\": float(MU * 252),  # annualized\n",
        "    \"SIGMA\": float(SIGMA * np.sqrt(252)),  # annualized\n",
        "    \"STEPS\": STEPS,\n",
        "    \"N_PATHS\": N_PATHS,\n",
        "    \"backend\": b2,\n",
        "    \"runtime_seconds\": float(t2)\n",
        "}\n",
        "with open(\"../outputs/nvda_mc_meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(f\"✓ Saved: outputs/nvda_mc_meta.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sanity Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print last 5 rows of preprocessed data\n",
        "print(\"Last 5 rows of preprocessed data:\")\n",
        "print(df[[\"date\", \"close\", \"mu_rolling\", \"sigma_rolling\"]].tail())\n",
        "\n",
        "# Print ML R² and predictions\n",
        "print(f\"\\nML R² Score: {r2:.4f}\")\n",
        "print(f\"\\nFirst 5 ML predictions:\")\n",
        "print(ml_pred_df.head())\n",
        "\n",
        "# Print MC meta and quantiles\n",
        "print(f\"\\nMC Metadata:\")\n",
        "print(json.dumps(meta, indent=2))\n",
        "print(f\"\\nMC Terminal Price Quantiles:\")\n",
        "print(f\"  P5  = ${p5:.2f}\")\n",
        "print(f\"  P50 = ${p50:.2f}\")\n",
        "print(f\"  P95 = ${p95:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Monte Carlo: Year-by-Year Simulations\n",
        "\n",
        "For each year, run MC simulation using the **first day's** rolling μ/σ parameters, computing P5/P50/P95/VaR/CVaR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MC simulations for each year × setup combination\n",
        "STEPS = 252\n",
        "N_PATHS = 5000\n",
        "results_mc = []\n",
        "\n",
        "# Use fastest MC backend\n",
        "mc_func = simulate_paths_numba if NUMBA_AVAILABLE else simulate_paths_serial\n",
        "\n",
        "for test_year in test_years:\n",
        "    year_df = df[df['year'] == test_year]\n",
        "    if len(year_df) < 10:\n",
        "        continue\n",
        "    \n",
        "    # Get first day of the year's parameters\n",
        "    first_day = year_df.iloc[0]\n",
        "    S0 = first_day['close']\n",
        "    MU = first_day['mu_rolling']\n",
        "    SIGMA = first_day['sigma_rolling']\n",
        "    \n",
        "    if np.isnan(MU) or np.isnan(SIGMA):\n",
        "        print(f\"⚠ Skipping {test_year}: NaN parameters\")\n",
        "        continue\n",
        "    \n",
        "    # Run MC simulation\n",
        "    paths = mc_func(MU, SIGMA, S0, STEPS, N_PATHS, dt=1/252)\n",
        "    terminals = paths[:, -1]\n",
        "    \n",
        "    # Calculate quantiles\n",
        "    p5, p50, p95 = np.percentile(terminals, [5, 50, 95])\n",
        "    \n",
        "    # Calculate VaR (5% tail) and CVaR (expected loss beyond VaR)\n",
        "    var_5 = np.percentile(terminals, 5)\n",
        "    cvar_5 = terminals[terminals <= var_5].mean()\n",
        "    \n",
        "    # Calculate bandwidth (relative uncertainty)\n",
        "    bandwidth = (p95 - p5) / p50\n",
        "    \n",
        "    results_mc.append({\n",
        "        'year': test_year,\n",
        "        'S0': S0,\n",
        "        'MU_annualized': MU * 252,\n",
        "        'SIGMA_annualized': SIGMA * np.sqrt(252),\n",
        "        'P5': p5,\n",
        "        'P50': p50,\n",
        "        'P95': p95,\n",
        "        'VaR_5': var_5,\n",
        "        'CVaR_5': cvar_5,\n",
        "        'bandwidth': bandwidth\n",
        "    })\n",
        "    \n",
        "    print(f\"{test_year}: P50=${p50:.2f}, bandwidth={bandwidth:.4f}\")\n",
        "\n",
        "# Save MC results\n",
        "results_mc_df = pd.DataFrame(results_mc)\n",
        "results_mc_df.to_csv(\"../outputs/results_mc.csv\", index=False)\n",
        "print(f\"\\n✓ Saved: outputs/results_mc.csv\")\n",
        "results_mc_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Comparative Visualization: Sign Accuracy & Bandwidth Over Years\n",
        "\n",
        "Plot sign_acc (model stability) and bandwidth (uncertainty expansion) across years\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results\n",
        "results_forecast_df = pd.read_csv(\"../outputs/results_forecast.csv\")\n",
        "results_mc_df = pd.read_csv(\"../outputs/results_mc.csv\")\n",
        "\n",
        "# Create comparative visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# Plot 1: Sign accuracy by year and setup\n",
        "for setup in results_forecast_df['setup'].unique():\n",
        "    subset = results_forecast_df[results_forecast_df['setup'] == setup]\n",
        "    ax1.plot(subset['year'], subset['sign_acc'], marker='o', label=setup, linewidth=2, markersize=6)\n",
        "ax1.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='Random (50%)')\n",
        "ax1.set_xlabel('Year')\n",
        "ax1.set_ylabel('Sign Accuracy')\n",
        "ax1.set_title('Model Stability: Sign Accuracy Over Years')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "ax1.set_ylim([0.4, 0.6])\n",
        "\n",
        "# Plot 2: Bandwidth (uncertainty) over years\n",
        "ax2.plot(results_mc_df['year'], results_mc_df['bandwidth'], marker='s', color='red', linewidth=2, markersize=8)\n",
        "ax2.fill_between(results_mc_df['year'], 0, results_mc_df['bandwidth'], alpha=0.2, color='red')\n",
        "ax2.set_xlabel('Year')\n",
        "ax2.set_ylabel('Bandwidth = (P95-P5)/P50')\n",
        "ax2.set_title('Market Uncertainty: Bandwidth Over Years')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"../outputs/figs/general/comparison_yearly.png\", dpi=150, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figs/general/comparison_yearly.png\")\n",
        "plt.show()\n",
        "\n",
        "# Merge results and save\n",
        "results_all = results_forecast_df.merge(results_mc_df[['year', 'bandwidth']], on='year', how='outer')\n",
        "results_all.to_csv(\"../outputs/results_all.csv\", index=False)\n",
        "print(f\"\\n✓ Saved: outputs/results_all.csv\")\n",
        "results_all\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
